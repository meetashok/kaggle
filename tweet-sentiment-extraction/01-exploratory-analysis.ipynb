{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition page\n",
    "https://www.kaggle.com/c/tweet-sentiment-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using following notebooks for inspiration\n",
    "\n",
    "- https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data\"\n",
    "train, test, sample = utils.read_data(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of `train` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head of `test` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head of `sample_submission`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Records in train = {train.index.size:6,}\")\n",
    "print(f\"Records in test  = {test.index.size:6,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of different sentiments\n",
    "Proportions are similar between train and test datasets with neutral sentiment as the dominant one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(16, 6)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=figsize, sharey=False)\n",
    "\n",
    "for ax, data, title in zip(axes, (train, test), (\"train\", \"test\")):\n",
    "    (train\n",
    "     .sentiment\n",
    "     .value_counts(normalize=True)\n",
    "     .reset_index()\n",
    "     .pipe((sns.barplot, \"data\"), x=\"index\", y=\"sentiment\", ax=ax)\n",
    "    )\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence lengths (letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of lengths of the `text` and `selected_text` strings\n",
    "While the distribution of `text` field is fairly uniform, the distribution of `selected_text` is skewed to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "for ax, col in zip(axes, (\"text\", \"selected_text\")):\n",
    "    (train\n",
    "     .assign(\n",
    "         length=lambda x: x.apply(lambda x: len(str(x[col])), axis=1),\n",
    "     )\n",
    "     .length\n",
    "     .pipe((sns.distplot), ax=ax, label=col)\n",
    "    )\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we see the distributions broken down by sentiment\n",
    "The distribution for neutral sentiment for `selected_text` is interesting that it isn't positively skewed but more uniform like the distributions of the `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "for ax, col in zip(axes, (\"text\", \"selected_text\")):\n",
    "    for sentiment in (\"positive\", \"negative\", \"neutral\"):\n",
    "        (train\n",
    "         .query(\"sentiment == @sentiment\")\n",
    "         .assign(\n",
    "             length=lambda x: x.apply(lambda x: len(str(x[col])), axis=1),\n",
    "         )\n",
    "         .length\n",
    "         .pipe((sns.kdeplot, \"data\"), ax=ax, label=sentiment, shade=True)\n",
    "        )\n",
    "        ax.set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of number of words of the `text` and `selected_text` strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "for ax, col in zip(axes, (\"text\", \"selected_text\")):\n",
    "    (train\n",
    "     .dropna()\n",
    "     .assign(\n",
    "         length=lambda x: x.apply(lambda x: len(str(x[col]).split()), axis=1),\n",
    "     )\n",
    "     .length\n",
    "     .pipe(sns.distplot, ax=ax, label=col, kde=False, bins=30)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we see the distributions broken down by sentiment\n",
    "The distribution for neutral sentiment for `selected_text` is interesting that it isn't positively skewed but more uniform like the distributions of the `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "for ax, col in zip(axes, (\"text\", \"selected_text\")):\n",
    "    for sentiment in (\"positive\", \"negative\", \"neutral\"):\n",
    "        (train\n",
    "         .query(\"sentiment == @sentiment\")\n",
    "         .assign(\n",
    "             length=lambda x: x.apply(lambda x: len(str(x[col]).split()), axis=1),\n",
    "         )\n",
    "         .length\n",
    "         .pipe((sns.kdeplot, \"data\"), ax=ax, label=sentiment, shade=True)\n",
    "        )\n",
    "        ax.set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These plots show the distributions for number of words but separated by sentiments\n",
    "The distribution of `text` and `selected_text` follows a very similar pattern which indicates that the `text` as is could be used for `selected_text` if the sentiment is neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "for ax, sentiment in zip(axes, (\"positive\", \"negative\", \"neutral\")):\n",
    "    for col in (\"text\", \"selected_text\"):\n",
    "        (train\n",
    "         .query(\"sentiment == @sentiment\")\n",
    "         .assign(\n",
    "             length=lambda x: x.apply(lambda x: len(str(x[col]).split()), axis=1),\n",
    "         )\n",
    "         .length\n",
    "         .pipe(sns.distplot, ax=ax, label=col)\n",
    "        )\n",
    "        ax.set_title(sentiment)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jaccard = (train\n",
    " .dropna()\n",
    " .assign(\n",
    "     jaccard=lambda x: x.apply(lambda x: utils.jaccard_similarity(x.text, x.selected_text), axis=1),\n",
    "     words_text=lambda x: x.apply(lambda x: len(x.text.split()), axis=1),\n",
    "     words_st_text=lambda x: x.apply(lambda x: len(x.text.split()), axis=1)\n",
    " )\n",
    ")\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "\n",
    "for num_words, row in zip((2, 100), axes):\n",
    "    for sentiment, ax in zip((\"positive\", \"negative\", \"neutral\"), row):\n",
    "        (data_jaccard\n",
    "         .query(\"sentiment == @sentiment\")\n",
    "         .query(\"words_text <= @num_words\")\n",
    "         .jaccard\n",
    "         .pipe(sns.distplot, ax=ax, kde=False)\n",
    "        )\n",
    "        ax.set_title(f\"Num_words <= {num_words}, {sentiment}\")\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for sentiment, ax in zip((\"positive\", \"negative\", \"neutral\"), axes):\n",
    "    (data_jaccard\n",
    "     .query(\"sentiment == @sentiment\")\n",
    "     .pipe((sns.lineplot, \"data\"), x=\"words_text\", y=\"jaccard\", estimator=\"mean\", ax=ax)\n",
    "    )\n",
    "    ax.set_title(f\"Sentiment: {sentiment}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample a few records where jaccard score is less than 1.0 for neutral sentiments. As we can see there is some behaviour that doesn't fit a pattern. \n",
    "- For some cases the only different is punctuation\n",
    "- For few cases, the first letter has been removed in selected_text\n",
    "\n",
    "One key insight is that any links have been completely removed in selected_text and hence should be filtered our during data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_jaccard\n",
    " .query(\"sentiment == 'positive'\")\n",
    " .query(\"jaccard < 1.0\")\n",
    " .sort_values(\"jaccard\")[[\"text\", \"selected_text\", \"jaccard\", \"words_text\"]]\n",
    " .head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top words in `text` in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = (train\n",
    " .text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "positive = (train\n",
    " .query(\"sentiment == 'positive'\")\n",
    " .text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "negative = (train\n",
    " .query(\"sentiment == 'negative'\")\n",
    " .text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "neutral = (train\n",
    " .query(\"sentiment == 'neutral'\")\n",
    " .text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "top_overall = Counter([item for row in overall for item in row if item not in stopwords.words(\"english\")])\n",
    "top_positive = Counter([item for row in positive for item in row if item not in stopwords.words(\"english\")])\n",
    "top_negative = Counter([item for row in negative for item in row if item not in stopwords.words(\"english\")])\n",
    "top_neutral = Counter([item for row in neutral for item in row if item not in stopwords.words(\"english\")])\n",
    "\n",
    "(\n",
    "    pd.concat((\n",
    "    pd.DataFrame(top_overall.most_common(20), columns=[\"overall\", \"count\"]),\n",
    "    pd.DataFrame(top_positive.most_common(20), columns=[\"positive\", \"count\"]),\n",
    "    pd.DataFrame(top_negative.most_common(20), columns=[\"negative\", \"count\"]),\n",
    "    pd.DataFrame(top_neutral.most_common(20), columns=[\"neutral\", \"count\"])),\n",
    "    axis=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top words in `selected_text` for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "overall = (train\n",
    " .selected_text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "positive = (train\n",
    " .query(\"sentiment == 'positive'\")\n",
    " .selected_text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "negative = (train\n",
    " .query(\"sentiment == 'negative'\")\n",
    " .selected_text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "neutral = (train\n",
    " .query(\"sentiment == 'neutral'\")\n",
    " .selected_text\n",
    " .apply(utils.clean_text)\n",
    " .apply(lambda x: x.split())\n",
    " .values\n",
    ")\n",
    "\n",
    "top_overall = Counter([item for row in overall for item in row if item not in stopwords.words(\"english\")])\n",
    "top_positive = Counter([item for row in positive for item in row if item not in stopwords.words(\"english\")])\n",
    "top_negative = Counter([item for row in negative for item in row if item not in stopwords.words(\"english\")])\n",
    "top_neutral = Counter([item for row in neutral for item in row if item not in stopwords.words(\"english\")])\n",
    "\n",
    "(\n",
    "    pd.concat((\n",
    "    pd.DataFrame(top_overall.most_common(20), columns=[\"overall\", \"count\"]),\n",
    "    pd.DataFrame(top_positive.most_common(20), columns=[\"positive\", \"count\"]),\n",
    "    pd.DataFrame(top_negative.most_common(20), columns=[\"negative\", \"count\"]),\n",
    "    pd.DataFrame(top_neutral.most_common(20), columns=[\"neutral\", \"count\"])),\n",
    "    axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does `selected_text` contain hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     578\n",
      "positive    409\n",
      "negative    233\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral     344\n",
       "negative      3\n",
       "positive      3\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lower = (train\n",
    " .dropna()\n",
    " .assign(\n",
    "     text=lambda x: x.text.apply(lambda x: x.lower()),\n",
    "     selected_text=lambda x: x.selected_text.apply(lambda x: x.lower())\n",
    " )\n",
    ")\n",
    "\n",
    "search = \"http://\"\n",
    "\n",
    "print(data_lower[data_lower.text.str.contains(search)].sentiment.value_counts())\n",
    "data_lower[data_lower.text.str.contains(search) & data_lower.selected_text.str.contains(search)].sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = Counter([letter for sent in data_lower.text.values for letter in sent])\n",
    "letters.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashok/anaconda3/envs/kaggle-sentiment/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>cc73efff2b</td>\n",
       "      <td>this song is a slap on you face!!  ? http://bl...</td>\n",
       "      <td>this song is a slap on you face!!  ? http://bl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>a8ed4e8266</td>\n",
       "      <td>wants see my friends  ;-) http://plurk.com/p/w...</td>\n",
       "      <td>wants see my friends  ;-) http://plurk.com/p/w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20376</th>\n",
       "      <td>1e4dd145b3</td>\n",
       "      <td>http://twitpic.com/674p1 -  this is my ohio is...</td>\n",
       "      <td>http://twitpic.com/674p1 -  this is my ohio is...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22853</th>\n",
       "      <td>b31ee23c1c</td>\n",
       "      <td>daddy just left.................without me  ht...</td>\n",
       "      <td>daddy just left.................without me  ht...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24374</th>\n",
       "      <td>38a69ed9ec</td>\n",
       "      <td>add me up: http://profiles.friendster.com/amer...</td>\n",
       "      <td>add me up: http://profiles.friendster.com/amer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26430</th>\n",
       "      <td>8223259736</td>\n",
       "      <td>located &amp; ordered a new cooker today. feel i`v...</td>\n",
       "      <td>feel i`ve got a real bargain from http://www.l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "3310   cc73efff2b  this song is a slap on you face!!  ? http://bl...   \n",
       "4741   a8ed4e8266  wants see my friends  ;-) http://plurk.com/p/w...   \n",
       "20376  1e4dd145b3  http://twitpic.com/674p1 -  this is my ohio is...   \n",
       "22853  b31ee23c1c  daddy just left.................without me  ht...   \n",
       "24374  38a69ed9ec  add me up: http://profiles.friendster.com/amer...   \n",
       "26430  8223259736  located & ordered a new cooker today. feel i`v...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "3310   this song is a slap on you face!!  ? http://bl...  negative  \n",
       "4741   wants see my friends  ;-) http://plurk.com/p/w...  positive  \n",
       "20376  http://twitpic.com/674p1 -  this is my ohio is...  negative  \n",
       "22853  daddy just left.................without me  ht...  negative  \n",
       "24374  add me up: http://profiles.friendster.com/amer...  positive  \n",
       "26430  feel i`ve got a real bargain from http://www.l...  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lower.query(\"sentiment != 'neutral'\")[data_lower.text.str.contains(search) & data_lower.selected_text.str.contains(search)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many words are only special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      I`d have responded, if I were going\n",
       "1            Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                my boss is bullying me...\n",
       "3                           what interview! leave me alone\n",
       "4         Sons of ****, why couldn`t they put them on t...\n",
       "                               ...                        \n",
       "27476     wish we could come see u on Denver  husband l...\n",
       "27477     I`ve wondered about rake to.  The client has ...\n",
       "27478     Yay good for both of you. Enjoy the break - y...\n",
       "27479                           But it was worth it  ****.\n",
       "27480       All this flirting going on - The ATG smiles...\n",
       "Name: text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['`', ',']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[%s]\" % re.escape(string.punctuation), train.iloc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
