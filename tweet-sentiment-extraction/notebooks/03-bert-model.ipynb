{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import (BertModel, \n",
    "                          BertConfig, \n",
    "                          RobertaConfig, \n",
    "                          RobertaModel)\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d308cfd241c74ee0aa05bd55dc762b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f46c52e2084474a028fb43be248d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "roberta_config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "roberta_config.output_attentions = False\n",
    "roberta_config.output_hidden_states = True\n",
    "roberta_config.output_past = True\n",
    "\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\", config=roberta_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(datadir):\n",
    "    train = pd.read_csv(os.path.join(datadir, \"train.csv\"))\n",
    "    test = pd.read_csv(os.path.join(datadir, \"test.csv\"))\n",
    "    sample_submission = pd.read_csv(os.path.join(datadir, \"sample_submission.csv\"))\n",
    "\n",
    "    return (train, test, sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, _ = read_data(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx\n",
      "Yay good for both of you.\n"
     ]
    }
   ],
   "source": [
    "pos = train.iloc[27478]\n",
    "text, st = pos.text, pos.selected_text\n",
    "\n",
    "print(text)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1fe991f39f44158eb3d8f73a16ef20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89d962e199b4b4993adfb19196d957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d462540be2441e3b810f0e2af75704d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bpe_tokenizer = ByteLevelBPETokenizer(\n",
    "            vocab_file=\"../pretrained/roberta-base-vocab.json\",\n",
    "            merges_file=\"../pretrained/roberta-base-merges.txt\",\n",
    "            lowercase=True,\n",
    "            add_prefix_space=True,\n",
    "        )\n",
    "\n",
    "roberta_tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "\n",
    "ids = np.ones((1, MAX_LEN), dtype=np.int32)\n",
    "attention_mask = np.zeros((1, MAX_LEN), dtype=np.int32)\n",
    "token_type_ids = np.zeros((1, MAX_LEN), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = bpe_tokenizer.encode(text)\n",
    "\n",
    "# encode_length = 1 + len(encoded.ids) + 2 + 1 + 1\n",
    "\n",
    "# ids[0,:encode_length] = [0] + encoded.ids + [2, 2] + [1331] + [1]\n",
    "# attention_mask[0,:encode_length] = [1] * encode_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = roberta_tokenizer.build_inputs_with_special_tokens(bpe_tokenizer.encode(text).ids, \n",
    "                                                      bpe_tokenizer.encode('positive').ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = roberta_tokenizer.create_token_type_ids_from_sequences(bpe_tokenizer.encode(text).ids, \n",
    "                                                      bpe_tokenizer.encode('positive').ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "\n",
    "encoded = bpe_tokenizer.encode(text)\n",
    "\n",
    "ids = torch.tensor([encoded.ids])\n",
    "mask = torch.tensor([encoded.attention_mask])\n",
    "token_type_ids = torch.tensor([encoded.type_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = roberta(ids, attention_mask=mask, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-94de41e5168c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlengths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ids'"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for _, row in train.iterrows():\n",
    "    if isinstance(row.text, str):\n",
    "        encoded = roberta_tokenizer.encode(row.text)\n",
    "        lengths += [len(encoded.ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(12,4))\n",
    "sns.countplot(lengths, ax=ax)\n",
    "\n",
    "print(f\"Maximum token size: {max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    tweet = \" \" + \" \".join(str(tweet).split())\n",
    "    selected_text = \" \" + \" \".join(str(selected_text).split())\n",
    "\n",
    "    len_st = len(selected_text) - 1\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "\n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "    \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids\n",
    "    tweet_offsets = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "    \n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "\n",
    "    sentiment_id = {\n",
    "        'positive': 1313,\n",
    "        'negative': 2430,\n",
    "        'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 4\n",
    "    targets_end += 4\n",
    "\n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "    \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    datadir = \"../data\"\n",
    "    modelsdir = \"../models\"\n",
    "    roberta_vocab = \"../pretrained/roberta-base-vocab.json\"\n",
    "    roberta_merges = \"../pretrained/roberta-base-merges.txt\"\n",
    "\n",
    "\n",
    "def initialize_tokenizer():\n",
    "    print(\"Tokenizer getting loaded...\")\n",
    "\n",
    "    tokenizer = ByteLevelBPETokenizer(\n",
    "        vocab_file=Config.roberta_vocab,\n",
    "        merges_file=Config.roberta_merges,\n",
    "        lowercase=True,\n",
    "        add_prefix_space=True)\n",
    "\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    print(f\"Vocab size = {vocab_size:,}\")\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer getting loaded...\n",
      "Vocab size = 50,265\n"
     ]
    }
   ],
   "source": [
    "tokenizer = initialize_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(transformers.BertModel):\n",
    "    def __init__(self, config):\n",
    "        super(TweetModel, self).__init__(config)\n",
    "        print(\"Importing model...\")\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(config.hidden_size*2, 2)\n",
    "\n",
    "    def forward(self, ids, attention_mask, token_type_ids):\n",
    "        _, _, out = self.roberta(\n",
    "                        ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "        \n",
    "        out = torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.linear(out)\n",
    "\n",
    "        start, end = logits.split(1, dim=-1)\n",
    "\n",
    "        return start.squeeze(-1), end.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing model...\n"
     ]
    }
   ],
   "source": [
    "model = TweetModel(roberta_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0020, -0.0073,  0.0193,  ...,  0.0178,  0.0176, -0.0058],\n",
       "         [ 0.0056,  0.0164,  0.0112,  ...,  0.0035, -0.0208,  0.0130]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0026, -0.0124], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.linear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_config.output_hidden_states = True\n",
    "tweetmodel = TweetModel(roberta_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "\n",
    "encoded = bpe_tokenizer.encode(text)\n",
    "\n",
    "ids = torch.tensor([encoded.ids])\n",
    "attention_mask = torch.tensor([encoded.attention_mask])\n",
    "token_type_ids = torch.tensor([encoded.type_ids])\n",
    "\n",
    "logits = tweetmodel(ids, attention_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = logits[:,:,0], logits[:,:,1]\n",
    "ground = torch.zeros_like(start)\n",
    "ground[:,5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    tweet = \" \" + \" \".join(str(tweet).split())\n",
    "    selected_text = \" \" + \" \".join(str(selected_text).split())\n",
    "\n",
    "    len_st = len(selected_text) - 1\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "\n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "    \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids\n",
    "    tweet_offsets = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "    \n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "\n",
    "    sentiment_id = {\n",
    "        'positive': 1313,\n",
    "        'negative': 2430,\n",
    "        'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 4\n",
    "    targets_end += 4\n",
    "\n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "    \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    sentiment_ids = {\n",
    "            'positive': 1313, \n",
    "            'negative': 2430, \n",
    "            'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    # initializing ids, attention_mask, token_typel_ids\n",
    "    ids = np.zeros((max_len), dtype=np.int32)\n",
    "    attention_mask = np.zeros((max_len), dtype=np.int32)\n",
    "    token_type_ids = np.zeros((max_len), dtype=np.int32)\n",
    "    \n",
    "    # removing extra spaces and encoding tweet\n",
    "    tweet = \" \" + \" \".join(tweet.split())\n",
    "    selected_text = \" \".join(selected_text.split())\n",
    "    encoded_tweet = tokenizer.encode(tweet)\n",
    "        \n",
    "    # filling the ids and attention_mask\n",
    "    ids_valid = [0] + [sentiment_ids[sentiment]] + [2, 2] + encoded_tweet.ids + [2]\n",
    "    len_valid = len(ids_valid)\n",
    "    attention_mask_valid = [1] * len_valid\n",
    "\n",
    "    ids[:len_valid] = ids_valid\n",
    "    attention_mask[:len_valid] = attention_mask_valid\n",
    "    \n",
    "    \n",
    "    selected_text_len = len(selected_text)\n",
    "\n",
    "    for idx, char in enumerate(tweet):\n",
    "        if char == selected_text[0]:\n",
    "            if tweet[idx:selected_text_len+idx] == selected_text:\n",
    "                char_start = idx\n",
    "                char_end = char_start + selected_text_len\n",
    "\n",
    "    assert char_start is not None\n",
    "    assert char_end is not None\n",
    "    assert tweet[char_start:char_end] == selected_text\n",
    "        \n",
    "    for token_index, (offset_start, offset_end) in enumerate(encoded_tweet.offsets):\n",
    "        if (char_start >= offset_start) and (char_start <= offset_end):\n",
    "#             print(tweet[offset_start:offset_end], char_start, offset_start, offset_end, token_index)\n",
    "            token_start = token_index\n",
    "        if (char_end-1 >= offset_start) and (char_end <= offset_end):\n",
    "#             print(tweet[offset_start:offset_end], char_end, offset_start, offset_end, token_index)\n",
    "            token_end = token_index\n",
    "        \n",
    "    assert token_start is not None\n",
    "    assert token_end is not None\n",
    "#     print(bpe_tokenizer.decode(encoded_tweet.ids[token_start:(token_end+1)]))\n",
    "#     assert selected_text.lower() in bpe_tokenizer.decode(encoded_tweet.ids[token_start:(token_end+1)])\n",
    "    \n",
    "    token_start += 4\n",
    "    token_end += 4\n",
    "    \n",
    "    return {\n",
    "        \"ids\": ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"token_start\": token_start,\n",
    "        \"token_end\": token_end,\n",
    "        \"tweet\": tweet,\n",
    "        \"selected_text\": selected_text\n",
    "    }\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1495\n",
    "record = train.iloc[idx]\n",
    "tweet, selected_text, sentiment = record.text, record.selected_text, record.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vocï¿½ que sumiu forever do msn.\n",
      "vocï¿½ que sumiu forever do msn.\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(tweet)\n",
    "print(selected_text)\n",
    "print(len(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vocï¿½ que sumiu forever do ms\n"
     ]
    }
   ],
   "source": [
    "out1 = process_tweet(tweet, selected_text, sentiment, tokenizer, max_len)\n",
    "out2 = process_data(tweet, selected_text, sentiment, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 14)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[\"token_start\"], out1[\"token_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 14)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2[\"targets_start\"], out2[\"targets_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out2[\"mask\"]), sum(out1[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = bpe_tokenizer.encode(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " voc -- Ġvoc\n",
      "ï¿ -- Ã¯\n",
      "½ -- Â\n",
      "  -- ¿\n",
      "qu -- Â½\n",
      "e su -- Ġque\n",
      "miu  -- Ġsum\n",
      "fo -- iu\n",
      "rever do -- Ġforever\n",
      " ms -- Ġdo\n",
      "n. -- Ġms\n",
      " -- n\n",
      " -- .\n"
     ]
    }
   ],
   "source": [
    "for i, (o, token) in enumerate(zip(e.offsets, e.tokens)):\n",
    "    print(tweet[o[0]: o[1]], \"--\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.isascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27324"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train\n",
    " .dropna() \n",
    " .reset_index(drop=True)\n",
    " .assign(allascii=lambda x: x.text.apply(lambda x: x.isascii()))\n",
    " .allascii\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test\n",
    " .dropna() \n",
    " .reset_index(drop=True)\n",
    " .assign(allascii=lambda x: x.text.apply(lambda x: x.isascii()))\n",
    " .allascii\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27480"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3534"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005676855895196507"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27480 - 27324) / 27480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': array([    0,  7974,     2,     2, 28312, 29667,  4056,  9470, 14989,\n",
       "         1192,  6797,  9060,  6000,   109, 43601,   282,     4,     2,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0], dtype=int32),\n",
       " 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'token_type_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'token_start': 4,\n",
       " 'token_end': 14,\n",
       " 'tweet': ' vocï¿½ que sumiu forever do msn.',\n",
       " 'selected_text': 'vocï¿½ que sumiu forever do msn.'}"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  fold  \n",
       "0                    I`d have responded, if I were going   neutral     1  \n",
       "1                                               Sooo SAD  negative     5  \n",
       "2                                            bullying me  negative     1  \n",
       "3                                         leave me alone  negative     5  \n",
       "4                                          Sons of ****,  negative     1  \n",
       "...                                                  ...       ...   ...  \n",
       "27476                                             d lost  negative     1  \n",
       "27477                                      , don`t force  negative     3  \n",
       "27478                          Yay good for both of you.  positive     1  \n",
       "27479                         But it was worth it  ****.  positive     1  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral     4  \n",
       "\n",
       "[27481 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_indices(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>negative</th>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2224</td>\n",
       "      <td>2224</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1717</td>\n",
       "      <td>1717</td>\n",
       "      <td>1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>negative</th>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2224</td>\n",
       "      <td>2224</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1716</td>\n",
       "      <td>1716</td>\n",
       "      <td>1716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>negative</th>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2224</td>\n",
       "      <td>2224</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1716</td>\n",
       "      <td>1716</td>\n",
       "      <td>1716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>negative</th>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2223</td>\n",
       "      <td>2222</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1716</td>\n",
       "      <td>1716</td>\n",
       "      <td>1716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>negative</th>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2223</td>\n",
       "      <td>2223</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1717</td>\n",
       "      <td>1717</td>\n",
       "      <td>1717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                textID  text  selected_text\n",
       "fold sentiment                             \n",
       "1    negative     1556  1556           1556\n",
       "     neutral      2224  2224           2224\n",
       "     positive     1717  1717           1717\n",
       "2    negative     1556  1556           1556\n",
       "     neutral      2224  2224           2224\n",
       "     positive     1716  1716           1716\n",
       "3    negative     1556  1556           1556\n",
       "     neutral      2224  2224           2224\n",
       "     positive     1716  1716           1716\n",
       "4    negative     1557  1557           1557\n",
       "     neutral      2223  2222           2222\n",
       "     positive     1716  1716           1716\n",
       "5    negative     1556  1556           1556\n",
       "     neutral      2223  2223           2223\n",
       "     positive     1717  1717           1717"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.groupby([\"fold\", \"sentiment\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     3,     7, ..., 27458, 27463, 27465])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14660</th>\n",
       "      <td>000a596b74</td>\n",
       "      <td>wah....American Chocolate Cheese Cake for my c...</td>\n",
       "      <td>Cheese Cake for my chweet mummy ! muaxxx</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>000efa962a</td>\n",
       "      <td>I`m going to watch it now</td>\n",
       "      <td>I`m going to watch it now</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>002210304b</td>\n",
       "      <td>I`d Love to work with you! http://myspace.com...</td>\n",
       "      <td>I`d Love</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14546</th>\n",
       "      <td>0025cd3554</td>\n",
       "      <td>Might be in the middle of a perfect weekend...</td>\n",
       "      <td>perfect</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>002f1aaedf</td>\n",
       "      <td>I`m ready homie..actually ima be working</td>\n",
       "      <td>working</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13016</th>\n",
       "      <td>ff68d28c4d</td>\n",
       "      <td>That would have been fun BUT we were soooo TI...</td>\n",
       "      <td>soooo TIRED yesterday.  Long day at the office...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24890</th>\n",
       "      <td>ff6d7db82a</td>\n",
       "      <td>Back from SOAP, soooo fun.</td>\n",
       "      <td>soooo fun.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18821</th>\n",
       "      <td>ff7edd8115</td>\n",
       "      <td>Well now I`m gonna be on a mission to find th...</td>\n",
       "      <td>Well now I`m gonna be on a mission to find the...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24227</th>\n",
       "      <td>ff84fbc83d</td>\n",
       "      <td>Maybe you have, my memory sucks.</td>\n",
       "      <td>my memory sucks.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>ffcc809783</td>\n",
       "      <td>Follow Friday rickbaker24 i only have 6 friends</td>\n",
       "      <td>Follow Friday rickbaker24 i only have 6 friends</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5496 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "14660  000a596b74  wah....American Chocolate Cheese Cake for my c...   \n",
       "2953   000efa962a                          I`m going to watch it now   \n",
       "2300   002210304b   I`d Love to work with you! http://myspace.com...   \n",
       "14546  0025cd3554     Might be in the middle of a perfect weekend...   \n",
       "15686  002f1aaedf           I`m ready homie..actually ima be working   \n",
       "...           ...                                                ...   \n",
       "13016  ff68d28c4d   That would have been fun BUT we were soooo TI...   \n",
       "24890  ff6d7db82a                         Back from SOAP, soooo fun.   \n",
       "18821  ff7edd8115   Well now I`m gonna be on a mission to find th...   \n",
       "24227  ff84fbc83d                   Maybe you have, my memory sucks.   \n",
       "9089   ffcc809783    Follow Friday rickbaker24 i only have 6 friends   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "14660           Cheese Cake for my chweet mummy ! muaxxx  positive  \n",
       "2953                           I`m going to watch it now   neutral  \n",
       "2300                                            I`d Love  positive  \n",
       "14546                                            perfect  positive  \n",
       "15686                                            working  positive  \n",
       "...                                                  ...       ...  \n",
       "13016  soooo TIRED yesterday.  Long day at the office...  negative  \n",
       "24890                                         soooo fun.  positive  \n",
       "18821  Well now I`m gonna be on a mission to find the...   neutral  \n",
       "24227                                   my memory sucks.  negative  \n",
       "9089     Follow Friday rickbaker24 i only have 6 friends   neutral  \n",
       "\n",
       "[5496 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[right].sort_values(by='textID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.get_n_splits(X=np.arange(train.index.size), y=train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
